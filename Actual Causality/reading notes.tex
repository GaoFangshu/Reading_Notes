%-*- coding: UTF-8 -*-
\documentclass[UTF8]{ctexbook}


\usepackage{indentfirst}
\setlength{\parindent}{0.5cm}

\usepackage{graphicx}
\usepackage[top=1in, bottom=1.25in, left=1.25in, right=1.25in]{geometry}

%\usepackage{setspace}
%\renewcommand{\baselinestretch}{1.3}

%\usepackage{titling}
%\setlength{\droptitle}{-2cm}

\usepackage{subcaption} 
\usepackage{float}

\usepackage{mdframed}


\title{Reading Notes of \textit{Actual Causality}}
\author{Gao Fangshu}
\date{2019.4.27}

\begin{document}
\maketitle
\section*{Chapter 1. Introduction and Overview}
There are two notions of caulsality:
\begin{itemize}
\item \textit{type causality}: Also called \textit{general causality}. Type causality contains general staments, and allows people to make predictions (\textit{forward-looking}). 
\item \textit{actual causality}: Also called \textit{token causality} or \textit{specific causality}. Actual causality focus on particular events, and related to words such as "responsebility" and "blame".
\end{itemize}

Roughly speaking, reasoning about type causality is equivalent to reasoning about \textit{effects of causes} (possible effects of a given event), whereas reasoning about actual causality is equivalent to reasoning about \textit{causes of effects} (possible causes of a particular outcome).

``But-for" definition of causality: A is a cause of B if, but for A, B would not have happened. However, it is not always enough to determine causality, and \textit{Halpern-Pearl definition} solve some problems where but-for test fails.

\section*{Chapter 2. The HP Definition of Causality}
\subsection*{2.1 Causal Models}

\begin{mdframed}
\textbf{Definition of causal model}

A \textit{causal model} $M$ is a pair $(\mathcal{S}, \mathcal{F})$:
\begin{itemize}
	\item $\mathcal{S}$: A \textit{signature}, explicitly lists the endogenous and exogenous variables and characterizes their possible values. A signature $\mathcal{S}$ is a tuple ($\mathcal{U}$,$\mathcal{V}$,$\mathcal{R}$):
	\begin{itemize}
		\item $\mathcal{U}$: A set of exogenous variables
		\item $\mathcal{V}$: A set of endogenous variables
		\item $\mathcal{R}$: $\mathcal{R}$ maps variables in $\mathcal{U}$ or $\mathcal{V}$ into possible values for them (i.e., the set of values over which the variable ranges).
	\end{itemize}
	\item $\mathcal{F}$: A set of \textit{structural equations}. $\mathcal{F}$ associates with each endogenous variable $X \in \mathcal{V}$ a function denoted $F_{X}$ maps $\times_{Z \in(\mathcal{U} \cup \mathcal{V}-\{X\})} \mathcal{R}(Z)$ to $\mathcal{R}(X)$. That means, function $F_{X}$ captures a relation between all varaibles but for $X$ and $X$. $F_{X}$ determines the value of $X$, given the values of all the other variables in $\mathcal{U} \cup \mathcal{V}$. 
\end{itemize}
\end{mdframed}
	
The key role of the structural equations is that they allow us to determine what happens if things had been other than they were, perhaps due to an external intervention. In many examples, there is general agreement as to the appropriate causal model. The structural equations do not express actual causality; rather, they express the effects of interventions or, more generally, of variables taking on values other than their actual values. 

There may be  uncertainty of about the effects of interventions. All this uncertainty can be described by putting a probability on causal models and on the values of the exogenous variables. We can then talk about the probability that $A$ is a cause of $B$.

The dependencies between variables in a causal model $M$ can be described using a \textit{causal network} (sometimes called a \textit{causal graph}), consisting of nodes and directed edges. Informally, a model is said to be \textit{recursive} (or \textit{acyclic}) if there are no such dependency cycles (sometimes called \textit{feedback cycles}) among the variables. A \textit{strongly recursive} model is a model that if we know values of the exogenous variables, we know values of all variables else. The values of all variables are determined given a \textit{context}.

\begin{mdframed}
\textbf{Definition of recursive model}

First, we define \textit{partial order} $\preceq$: $X \preceq Y$  denotes that $X$ affects $Y$. The fact that $\preceq$ is a partial order means that $\preceq$ is a \textit{reflexive}, \textit{anti-symmetric}, and \textit{transitive} relation:
\begin{itemize}
	\item reflexive: $\forall X, X\preceq X$
	\item anti-symmetric: $X\preceq Y, Y\preceq X \Rightarrow X=Y$
	\item transitive: $X\preceq Y, Y\preceq Z \Rightarrow X\preceq Z$
\end{itemize}

Second, we define \textit{independency}: $Y$ is independent of $X$ in  $(M, \vec{u})$ if, for all settings $\vec{z}$ of the endogenous variables other than $X$ and $Y$, and all values $x$ and $x'$ of $X$, $F_{Y}(x, \vec{z}, \vec{u})=F_{Y}\left(x^{\prime}, \vec{z}, \vec{u}\right)$. That is, if we control all other variables, changing the value of $X$ cannot affect value of $Y$.

Then we define \textit{recursive model}: A model $M$ is recursive if, for each context (setting of the exogenous variables) $\vec{u}$, there is a partial order $\preceq_{\vec{u}}$ of the endogenous variables such that unless $X \preceq_{\vec{u}} Y$, $Y$ is independent of $X$ in $(M, \vec{u})$.

If M is a \textit{strongly recursive} model, then we can assume that all the partial orders $\preceq_{\vec{u}}$ are the same; in a recursive model, they may differ. 
\end{mdframed}

The choice of model can have a significant impact in determining causality ascriptions. $A$ may be a cause of $B$ relative to $(M, \vec{u})$ and not a cause of $B$ relative to $\left(M^{\prime}, \vec{u}^{\prime}\right)$.

\subsection*{2.2 A Formal Definition of Actual Cause}
We associate a causal formula $\varphi$ with a set of context . $[Y_{1} \leftarrow y_{1}, \dots, Y_{k} \leftarrow y_{k}] \varphi$ says that $\varphi$ would hold if $Y_i$ were set to $y_i$, for $i = 1,\dots,k$. A \textit{causal formula} (over $\mathcal{S}=(\mathcal{U}, \mathcal{V}, \mathcal{R})$) is one of the form $[Y_{1} \leftarrow y_{1}, \dots, Y_{k} \leftarrow y_{k}] \varphi$, where (1) $\varphi$ is a Boolean combination of primitive events; (2) $Y_{1}, \dots, Y_{k}$ are distinct variables in $\mathcal{V}$; (3) $y_{i} \in \mathcal{R}\left(Y_{i}\right)$. In a causal model, a causal formula $\varphi$ may be true or false.

For $\mathcal{S}=(\mathcal{U}, \mathcal{V}, \mathcal{R})$, let $\mathcal{L}(\mathcal{S})$ consist of all Boolean combinations of causal formulas, where the variables in the formulas are taken from $\mathcal{V}$ and the sets of possible values of these variables are determined by $\mathcal{R}$.

Let $(M, \vec{u}) \models \psi$ if the causal formula $\psi$ is true in the \textit{causal setting} $(M, \vec{u})$. Given a model $M$, the model that describes the result of the intervention setting variables in $\vec{Y}$ to $\vec{y}$ is $M_{\vec{Y} \leftarrow \vec{y}}$. If $\psi$ holds after the intervention, we have: $(M, \vec{u})\models[\vec{Y} \leftarrow \vec{y}] \psi$ iff $(M_{\vec{Y} \leftarrow \vec{y}}, \vec{u})\models\psi$.

The notation $(M, \vec{u}) \models \varphi$ is standard in the logic and philosophy communities. In the example of forest fire, $M^{d}$ is the disjunctive model. $\left(M^{d},(1,1)\right) \models [MD \leftarrow 0](FF=1)$, or $\left(M_{M D \leftarrow 0}^{d},(1,1)\right) \models [L \leftarrow 0 ; M D \leftarrow 0](F F=0)$, means that ``even if the arsonist is somehow prevented from dropping the match, the forest burns''.

\begin{mdframed}
\textbf{Three versions of HP definition of causality}
	
	$\vec{X}=\vec{x}$ is an actual cause of $\varphi$ in the causal setting $(M, \vec{u})$ if the following three conditions hold (three versions of HP definition are only different in AC2):

	\begin{itemize}
		\item AC1. $(M, \vec{u})\models(\vec{X}=\vec{x})$ and $(M, \vec{u})\models\varphi$
		\item AC2. See below:
		\begin{itemize}
		\item AC2(a). There is a partition of $\mathcal{V}$ (the set of endogenous variables) into two disjoint subsets $\vec{Z}$ and $\vec{W}($ so that $\vec{Z} \cap \vec{W}=\emptyset)$ with $\vec{X} \subseteq \vec{Z}$ and a setting $\vec{x}^{\prime}$ and $\vec{w}$ of the variables in $\vec{X}$ and $\vec{W},$ respectively, such that $(M, \vec{u})\models[\vec{X} \leftarrow \vec{x}^{\prime}, \vec{W} \leftarrow \vec{w}] \neg \varphi$
		\item AC2($\mathrm{b}^{o}$) (original). If $\vec{z}^{*}$ is such that $(M, \vec{u}) \models \vec{Z}=\vec{z}^{*},$ then for all subsets $\vec{Z}^{\prime}$ of $\vec{Z}-\vec{X},$ we have $(M, \vec{u})\models[\vec{X} \leftarrow \vec{x}, \vec{W} \leftarrow \vec{w}, \vec{Z}^{\prime} \leftarrow \vec{z}^{*}] \varphi$.
		\item AC2($\mathrm{b}^{u}$) (updated). If $\vec{z}^{*}$ is such that $(M, \vec{u})\models\vec{Z}=\vec{z}^{*},$ then for all subsets $\vec{W}^{\prime}$ of $\vec{W}$ and subsets $\vec{Z}^{\prime}$ of $\vec{Z}-\vec{X},$ we have $(M, \vec{u})\models[\vec{X} \leftarrow \vec{x}, \vec{W}^{\prime} \leftarrow \vec{w}, \vec{Z}^{\prime} \leftarrow \vec{z}^{*}] \varphi$
		\item AC2($\mathrm{a}^{m}$) (modified). There is a set $\vec{W}$ of variables in $\mathcal{V}$ and a setting $\vec{x}^{\prime}$ of the variables in $\vec{X}$ such that if $(M, \vec{u})\models\vec{W}=\vec{w}^{*},$ then $(M, \vec{u})\models[\vec{X} \leftarrow \vec{x}^{\prime}, \vec{W} \leftarrow \vec{w}^{*}] \neg \varphi$
		\end{itemize}
		\item AC3. $\vec{X}$ is minimal; there is no strict subset $\vec{X}^{\prime}$ of $\vec{X}$ such that $\vec{X}^{\prime}=\vec{x}^{\prime}$ satisfies condition
		ACl and AC2, where $\vec{x}^{\prime}$ is the restriction of $\vec{x}$ to the variables in $\vec{X}$ .
	\end{itemize}
	
\end{mdframed}

AC1 just says that $\vec{X}=\vec{x}$ cannot be considered a cause of $\varphi$ unless both $\vec{X}=\vec{x}$ and $\varphi$ actually happen.

AC2(a) is a necessity condition. It says that for $X = x$ to be a cause of $\varphi$, there must be a value $xâ€²$ in the range of $X$ such that if $X$ is set to $x'$, $\varphi$ no longer holds. This is the but-for clause; but for the fact that $X=x$ occurred, $\varphi$ would not have occurred.

AC2($\mathrm{b}^{o}$) says that changing $\vec{Z}$ (may due to setting $\vec{W}$ to $\vec{w}$, or some variables in $\vec{Z}$ are forced to their original values) does not affect $\varphi$; $\varphi$ continues to be true.

The only difference between AC2($\mathrm{b}^{o}$) and AC2($\mathrm{b}^{u}$) lies in the clause ``for all subsets $\vec{W}^{\prime}$ of $\vec{W}$'': AC2($\mathrm{b}^{u}$) must hold even if only a subset of $\vec{W}^{\prime}$ of the variables in $\vec{W}$ are set to their values in $\vec{w}$. This means that the variables in $\vec{W}-\vec{W}^{\prime}$ essentially act as they do in the real world; thar is, their values are determined by the structural equations, rather than being set to their values in $\vec{w}$.

AC3 is a minimality condition, which ensures that only those elements of the conjunction $\vec{X}=\vec{x}$ that are essential are considered part of a cause; inessential elements are pruned.



\end{document}