%-*- coding: UTF-8 -*-
\documentclass{article}

\usepackage{indentfirst}
\setlength{\parindent}{0.5cm}

\usepackage{graphicx}
\usepackage[top=1in, bottom=1.25in, left=1.25in, right=1.25in]{geometry}

%\usepackage{setspace}
%\renewcommand{\baselinestretch}{1.3}

%\usepackage{titling}
%\setlength{\droptitle}{-2cm}

\usepackage{subcaption} 
\usepackage{float}

\usepackage{mdframed}

\usepackage{amsmath}

\usepackage[dvipsnames]{xcolor}
\definecolor{gray}{gray}{0.5}

\title{Reading Notes of \textit{Causal Inference}\footnote{Hernán MA, Robins JM (2019). Causal Inference. Boca Raton: Chapman \& Hall/CRC, forthcoming.}}
\author{Gao Fangshu}
\date{2019.5.7}

\begin{document}
\maketitle
\part*{Causal inference without models}
\section{A definition of causal effect}
\subsection{Individual causal effects}
\begin{mdframed}
Causal effect for individual $i$: 
\begin{center}
	$Y_{i}^{a=1} \neq Y_{i}^{a=0}$
\end{center}
the treatment $A$ has a causal effect on an individual’s outcome $Y$ if $Y^{a=1} \neq Y^{a=0}$ for the individual.
\end{mdframed}

That is, for individual $i$,  $Y^{a=1}$ (is a random variable, read $Y$ under treatment $a=1$), the outcome variable that would have been observed under the treatment value $a=1$ is not equal to the outcome variable that would have been observed under the treatment value $a=0$ ($Y^{a=0}$). The variables  $Y^{a=1}$ and $Y^{a=0}$ are referred to as \textit{potential outcomes} or as \textit{counterfactual outcomes}. \textcolor{gray}{In economics, we often refer ``counterfactual outcomes'' to outcomes that had not happend. But here, both $Y^{a=0}$ and $Y^{a=1}$ are counterfactual outcomes, no matter auctually $a=0$ or $a=1$.}

The counterfactual outcomes that corresponds to the treatment value that the individual actually received is \textit{actually factual}.
\begin{mdframed}
Consistency:
\begin{center}
if $A_{i}=a,$ then $Y_{i}^{a}=Y^{A_{i}}=Y_{i}$
\end{center}
an individual with observed treatment $A=a$, has observed outcome $Y$ equal to his counterfactual outcome $Y^{a}$.
\end{mdframed}

\textcolor{gray}{Consistency is that the observed outcome is equal to what (we think that) would have been observed.}

In general, individual causal effects cannot be identified -- that is, cannot be expressed as a function of the observed data -- because of missing data. 

\subsection{Average causal effects}
\begin{mdframed}
Average causal effect in population:
\begin{center}
	$\mathrm{E}\left[Y^{a=1}\right] \neq \mathrm{E}\left[Y^{a=0}\right]$
\end{center}
\end{mdframed}

Absence of an average causal effect does not imply absence of individual effects. When there is no causal effect for any individual in the population, i.e., $Y^{a=1}=Y^{a=0}$ for all individuals, we say that the \textit{sharp causal null hypothesis} is true.  

Average causal effects can sometimes be identified from data, even if individual causal effects cannot.

\subsection{Measures of causal effect}
We can represent the causal null by: (1)  causal risk difference  $\operatorname{Pr}\left[Y^{a=1}=1\right]-\operatorname{Pr}\left[Y^{a=0}=1\right]=0$; (2) causal risk ratio  $\frac{\operatorname{Pr}\left[Y^{a=1}=1\right]}{\operatorname{Pr}\left[Y^{a=0}=1\right]}=1$; (3) causal odds ratio $\frac{\operatorname{Pr}\left[Y^{a=1}=1\right] / \operatorname{Pr}\left[Y^{a=1}=0\right]}{\operatorname{Pr}\left[Y^{a=0}=1\right] / \operatorname{Pr}\left[Y^{a=0}=0\right]}=1$.

These causal parameters quantify the strength of the same causal effect on different scales. Because the causal risk difference, risk ratio, and odds ratio (and other summaries) measure the causal effect, we refer to them as \textit{effect measures}.

\subsection{Random variability}
In causal inference, random error derives from sampling variability, nondeterministic counterfactuals, or both. 

$1^{\mathrm{st}}$ source of random error is \textit{sampling variability}. When we only have a random sample from a much larger, near-infinite population, $\operatorname{Pr}\left[Y^{a=0}=1\right]$ cannot be directly computed (instead, we have $\widehat{\operatorname{Pr}}\left[Y^{a=0}=1\right]$ from the sample, sometimes it is a consistent estimator of $\operatorname{Pr}\left[Y^{a=0}=1\right]$). 

$2^{\mathrm{nd}}$ source of random error is \textit{nondeterministic counterfactuals}. Counterfactual outcomes may be stochastic or nondeterministic.

\textcolor{red}{TODO:} Technical Point 1.2 \textbf{Nondeterministic counterfactuals} needs to be added.

\subsection{Causation versus association}
Some equivalent definitions of independence are: (1) associational
risk difference $\operatorname{Pr}[Y=1 | A=1]-\operatorname{Pr}[Y=1 | A=0]=0$; (2) associational risk ratio $\frac{\operatorname{Pr}[Y=1 | A=1]}{\operatorname{Pr}[Y=1 | A=0]}=1$; (3) associational odds ratio $\frac{\operatorname{Pr}[Y=1 | A=1] / \operatorname{Pr}[Y=0 | A=1]}{\operatorname{Pr}[Y=1 | A=0] / \operatorname{Pr}[Y=0 | A=0]}=1$. The left hand sides measure the association on different scales, and we refer to them as \textit{association measures}. 

For a continuous outcome $Y$ we define \textit{mean independence} between treatment and outcome as: $\mathrm{E}[Y | A=1]=\mathrm{E}[Y | A=0]$. Independence and mean independence are the same concept for dichotomous outcomes.

\begin{figure}[h]
		\centering
		\includegraphics[width=0.5\linewidth]{fig/001}
\end{figure}

As the figure shows, \textit{association} is defined by a different risk in two disjoint subsets of the population determined by the individuals’ actual treatment value ($A=1$ or $A=0$), whereas \textit{causation} is defined by a different risk in the same population under two different treatment values ($a=1$ or $a=0$). \textcolor{gray}{In economics, ``selection bias'' may be a problem for association.} In this book, the discrepancy between association and causation is referred as \textit{confounding}.


\section{Randomized experiments}
\subsection{Randomization}
In ideal randomized experiments, association is causation.

\begin{mdframed}
Exchangeability:
\begin{center}
	$Y^{a} \perp A$ for all $a$
\end{center}
\end{mdframed}

That is, the risk under the potential treatment value $a$ among the treated, $\operatorname{Pr}\left[Y^{a}=1 | A=1\right]$, equals the risk under the potential treatment value $a$ among the untreated, $\operatorname{Pr}\left[Y^{a}=1 | A=0\right]$, for both $a=0$ and $a=1$. \textcolor{gray}{$\operatorname{Pr}\left[Y^{a}=1 | A=1\right]$ means that we choose people by $A=1$, and observe their outcome with treatment value $a$.}

Randomization is so highly valued because it is expected to produce exchangeability. When the treated and the untreated are exchangeable, we sometimes say that treatment is exogenous, and thus \textit{exogeneity} is commonly used as a synonym for exchangeability.

Independence between the counterfactual outcome and the observed treatment $Y^{a} \perp A$ does not imply independence between the observed outcome and the observed treatment $Y \perp A$. For example, suppose there is a causal effect on some individuals so that $Y^{a=1} \neq Y^{a=0}$. Since $Y=Y^{A}$, then $Y^{a}$ with $a$ evaluated at the observed treatment $A$ is the observed $Y^{A}$, which depends on $A$ and thus will not be independent of $A$.

It is possible that a study is a randomized experiment even if exchangeability does not hold in
infinite samples. There may be two reasons: (1) the sample size is too small, random fluctuations arising from sampling variability could explain almost anything; (2) randomized experiments with more than one randomization step.

\subsection{Conditional randomization}
We call the experiments using a single unconditional (marginal) randomization probability that is common to all individuals as \textit{marginally randomized experiments}. And we call the experiments using several randomization probabilities that depend (are conditional) on the values of the variables as \textit{conditionally randomized experiments}.

Conditional randomization does not guarantee unconditional (or marginal) exchangeability $Y^{a} \perp A$, it guarantees \textit{conditional exchangeability} $Y^{a} \perp A | L$ within levels of the variable $L$.

\begin{mdframed}
Conditional exchangeability:
	\begin{center}
		$Y^{a} \perp A | L$ ($Y^{a} \perp A | L=l$ holds for all values $l$) for all $a$
	\end{center}
\end{mdframed}

We can compute the average causal effect in each of these subsets of strata of the population, for example, $\operatorname{Pr}\left[Y^{a=1}=1 | L=1\right] / \operatorname{Pr}\left[Y^{a=0}=1 | L=1\right]$ (however, we can compute the average causal effect $\operatorname{Pr}\left[Y^{a=1}=1\right] / \operatorname{Pr}\left[Y^{a=0}=1\right]$ in the entire population, if we  do not expect to have information on $L$ for future individuals). We refer to this method to compute stratum-specific causal effects as \textit{stratification}. Stratumspecific causal risk ratio in the subset $L=1$ may differ from the causal risk ratio in $L=0$. In that case, we say that the effect of treatment is modified by $L$, or that there is \textit{effect modification} by $L$. 

\subsection{Standardization}



\section{Observational studies}


\section{Effect modification}


\section{Interaction}


\section{Graphical representation of causal effects}


\section{Confounding}


\section{Selection bias}

\section{Measurement bias}

\section{Random variability}

\part*{Causal inference with models}
\section{Why model?}
\subsection{Data cannot speak for themselves}
We cannot always let the data “speak for themselves” to obtain a consistent estimate. Rather, we often need to supplement the data with a model. For example, we would not compute an estimator $\widehat{\mathrm{E}}[Y | A=a]$ of $\mathrm{E}[Y | A=a]$ when $A$ were a truly continuous variable, the sample average would be undefined for nearly all treatment levels.

\subsection{Parametric estimators}
A model is an a priori restriction on the distribution of the data. A parametric model is like adding information that is not in the data to compensate for the lack of sufficient information in the data themselves. 

Model-based causal inference relies on the condition of (approximately) \textit{no model misspecification}. Because parametric models are rarely, if ever, perfectly specified, certain degree of model misspecification is almost always expected.

\subsection{Nonparametric estimators}
Whenever the number of parameters in the model is equal to the number of population quantities that can be estimated by using the model, then the model is \textit{saturated}. A saturated model has the same number of unknowns in both sides of the equal sign. 

When a model has only a few parameters but it is used to estimate many population quantities, we say that the model is \textit{parsimonious}.

For causal inference, identifiability assumptions are the assumptions that we would have to make even if we had an infinite amount of data. Modeling assumptions are the assumptions that we have to make precisely because we do not have an infinite amount of data.

\subsection{The bias-variance trade-off}
In general, the larger the number of parameters in the model, the fewer restrictions the model imposes; the less smooth the model, the more protection afforded against bias from model misspecification. Although less smooth models may yield a less biased estimate, they also result in a larger variance, i.e., wider 95\% confidence intervals around the estimate. 

\textbf{Technical Point 11.1 (A taxonomy of commonly used models)}: Linear regression models are a subset of larger class of models: Generalized Linear Models. GLMs have three components: a linear functional form $\sum_{i=0}^{p} \theta_{i} X_{i},$ a link function $g\{\}$ such that $g\{\mathrm{E}[Y | X]\}=\sum_{i=1}^{p} \theta_{i} X_{i},$ and a distribution for the $Y$ conditional on $X .$ If we do not model the distribution of $Y$ conditional on $X,$ we refer to the model as a conditional mean model. We can restrict outcomes with different link functions (identity link, log link, logit link, etc.). \textcolor{gray}{There are interesting introductions, that we omit here, about generalized estimating equation (GEE) models, generalized additive models (GAMs) and kernel regression models.}
\section{IP weighting and marginal structural models}

\section{Standardization and the parametric g-formula}

\section{G-estimation of structural nested models}

\section{Outcome regression and propensity scores}
Outcome regression and propensity scores are commonly used but have limited applicability for complex longitudinal data.

\subsection{Outcome regression}

\subsection{Propensity scores}
If the distribution of $p(L)$ were the same for the treated $A=1$ and the untreated $A=0$, then there would be no confounding due to $L$, i.e., there would be no open path from $L$ to $A$ on a causal diagram.

Individuals with same propensity score $p(L)$ will generally have different values of some covariates $L$. For example, two individuals with $p(L)=0.2$ may differ with respect to smoking intensity and exercise, and yet they may be equally likely to quit smoking given all the variables in $L$. That is, both individuals have the same conditional probability of ending up in the treated group $A=1$. If we consider all individuals with a given value of $p(L)$ in the superpopulation, this group will include individuals with different values of $L$ (e.g., different values of smoking intensity and exercise), but the distribution of $L$ will be the same in the treated and the untreated, that is, $A \perp L | p(L)$. We say the propensity score balances the covariates between the treated and the untreated.

\subsection{Propensity stratification and standardization}

\subsection{Propensity matching}
Defining closeness in propensity matching entails a bias-variance trade-off.

Using propensity scores to detect the overlapping range of the treated and the untreated may be useful, but simply restricting the study population to that range is a lazy way to ensure positivity. The automatic positivity ensured by propensity matching needs to be weighed against the difficulty of assessing transportability when restriction is solely based on the value of the estimated propensity scores.

\subsection{Propensity models, structural models, predictive models}
Propensity models are models for the probability of treatment $A$ given the variables $L$ used to try to achieve conditional exchangeability.

The dual use of outcome regression in both causal inference method and in prediction has led to many misunderstandings. One of the most important misunderstandings has to do with variable selection procedures. When the interest lies exclusively on outcome prediction, investigators want to select any variables that, when included as covariates in the model, improve its predictive ability. Many well-known variable selection procedures –– e.g., forward selection, backward elimination, stepwise selection –– and more recent developments in machine learning are used to enhance prediction. These are powerful tools for investigators who are interested in prediction, especially when dealing with very high-dimensional data.  A possible result of this mismatch is the inclusion of superfluous –– or even harmful –– covariates in propensity models and structural models. Specifically, the application of predictive algorithms to causal inference models may result in inflated variances.

Propensity models do not need to predict treatment very well. They just need to include the variables $L$ that guarantee exchangeability. Covariates that are strongly associated with treatment, but are not necessary to guarantee exchangeability, do not help reduce bias. If these covariates were included in $L$, adjustment can actually result in estimates with very large variances. \textcolor{gray}{Only variables that influence simultaneously the participation decision and the outcome variable should be included. It should also be clear that only variables that are unaffected by participation (or the anticipation of it) should be included in the model. To ensure this, variables should either be fixed over time or measured before participation.(Caliendo \& Kopeinig, 2008)}

Besides variance inflation, a predictive attitude towards variable selection for causal inference models –– both propensity models and outcome regression models –– may also result in self-inflicted bias.

\section{Instrumental variable estimation}

\section{Causal survival analysis}

\section{Variable selection for causal inference}

\end{document}